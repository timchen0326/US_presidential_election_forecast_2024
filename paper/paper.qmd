---
title: "Forecasting the 2024 U.S. Presidential Election"
subtitle: "Modeling State-Level Polling Data to Forecast the Electoral College Outcome"
author: 
  - Tim Chen
  - Steven Li
  - Tommy Fu
thanks: "Code and data are available at: https://github.com/timchen0326/US_presidential_election_forecast_2024.git."
date: today
date-format: long
abstract: "We forecast the outcome of the 2024 U.S. Presidential Election between Kamala Harris and Donald Trump by developing multiple linear regression models based on comprehensive polling data collected throughout the election cycle. Incorporating variables such as state-level demographics, pollster reliability scores, transparency scores, and sample sizes, we applied the same statistical model to both candidates to ensure consistent comparison. Our analysis predicts that Kamala Harris will receive 216 electoral votes, while Donald Trump is projected to secure 147 electoral votes. Neither candidate achieves the 270 electoral votes required to win the presidency, highlighting the potential for a closely contested election. These findings underscore the significant impact of state-specific factors on voter support and suggest that neither candidate currently holds a decisive advantage. We recommend that future research includes dynamic modeling techniques and additional predictive variables, such as economic indicators and voter turnout rates, to enhance the accuracy of election forecasts. Our study emphasizes the complexities involved in electoral predictions and the necessity of balancing multiple factors in policy design and electoral analysis."
format: pdf
number-sections: true
toc: true
bibliography: references.bib
editor: 
  markdown: 
    wrap: sentence
---

```{r}
#| include: false
#| warning: false
#| message: false
# Set a CRAN mirror
# Set a specific CRAN mirror (this example uses the US CRAN mirror)

options(repos = c(CRAN = "https://cran.rstudio.com/"))

library(tidyverse)
library(ggplot2)
library(janitor)
library(modelsummary)
library(here)
library(dplyr)
library(knitr)
library(car)

# Load the dataset
data <- read.csv(here::here("data/02-analysis_data/analysis_data.csv"))

```

\newpage
# Introduction

Forecasting elections has long been one of the most challenging tasks for political scientists, statisticians, and analysts alike. The complexity of predicting voter behavior in large, diverse electorates like that of the United States stems from numerous factors, including ever-shifting public opinion, rapidly changing political climates, and varying levels of voter engagement. The 2024 U.S. Presidential Election is no exception. With polarized voter bases, unpredictable external factors, and the growing influence of non-traditional media, the race remains highly uncertain, making reliable forecasting models more important—and difficult—than ever.

Central to any electoral forecast is the use of polling data. Polls provide snapshots of voter intentions at specific points in time, shaping both public perceptions and expert expectations. Yet, polling comes with its own set of challenges. Pollsters employ different methodologies—ranging from online surveys to phone interviews—each with its own inherent biases. Sample populations may vary in size and representativeness, potentially skewing results in favor of certain demographic groups. Moreover, polling accuracy can be further complicated by factors such as non-response bias, the changing nature of the electorate, and the rise of unconventional voting patterns, particularly among younger and minority voters.

In this paper, we attempt to forecast the outcome of the 2024 U.S. Presidential Election by developing statistical models based on polling data from a variety of sources. By leveraging multiple linear regression models, we aim to predict the percentage of support for the main candidates—Kamala Harris and Donald Trump—across different states. Our analysis incorporates key variables such as pollster reliability, sample size, and state-level demographics, all of which contribute to shaping the electoral landscape. Ultimately, we aggregate these state-level predictions to simulate the outcome of the Electoral College, providing insights into the likelihood of either candidate securing the 270 votes required to win the presidency.

The rest of this paper is structured as follows: @sec-data discusses the data used for this analysis, including key variables and sources. @sec-model outlines the models developed for each candidate and presents the corresponding results.
@sec-predict discusses the aggregated Electoral College predictions based on the model outputs. Finally, @sec-discuss provides conclusions and offers suggestions for future research.

# Data {#sec-data}

## Overview

The dataset employed in this analysis encompasses polling data from various reputable sources, capturing critical variables related to polling organizations, sample sizes, candidate support levels, and polling coverage (state-level or national). The primary variables of interest are outlined as follows:

- **Poll ID**: A unique identifier for each poll entry, facilitating data tracking and management (e.g., 88590).
- **Pollster**: The organization conducting the poll, which serves as a primary indicator of the poll’s methodological quality (e.g., YouGov, Ipsos).
- **Pollscore**: A quantitative measure of the pollster’s reliability, where lower (negative) values suggest higher predictive accuracy (e.g., -1.1 for YouGov).
- **Sample Size**: The number of respondents included in each poll, influencing the statistical precision and margin of error (e.g., 1414).
- **Support Percentage (pct)**: The proportion of respondents expressing support for each candidate, serving as the dependent variable in subsequent analyses (e.g., 47% for Kamala Harris).
- **State**: Indicates the geographical focus of the poll, either at the state level or nationwide (e.g., National).
- **Candidate Name**: The candidate assessed in the poll, providing context for support levels and enabling candidate-specific analyses (e.g., Kamala Harris, Donald Trump).
- **End Date**: The date on which the poll concluded, offering temporal alignment for longitudinal analyses (e.g., 2024-10-07).

To ensure analytical rigor, the dataset underwent extensive preprocessing. This involved standardizing variable formats for compatibility with regression models, converting support percentages into numerical values, and systematically addressing missing data to minimize bias. These preprocessing steps ensured that the dataset adhered to the standards of a "tidy" dataset, enabling robust model development and enhancing interpretability of subsequent statistical analyses.

@tbl-overview_data shows a sample of the dataset. 


## Measurement and Limitations

The primary limitations of this analysis stem from the quality and variability of polling data, which can introduce biases through factors like sample size and pollster methodology. Additionally, the model provides a static snapshot of voter preferences, without accounting for the dynamic nature of elections For instance, shifts in public opinion over time or the impact of campaign events. The exclusion of key external factors, such as economic conditions or voter turnout, also limits the model's ability to fully capture the complexities of election outcomes. Furthermore, the simplified Electoral College simulation assumes that polling data will accurately predict state-level results, which may not always be the case, especially in battleground states with volatile voter behavior.



## Outcome variables
Our primary outcome variable is the percentage of support for Kamala Harris and Donald Trump in each poll. This variable is central to our analysis because it directly captures voter preference, which is the most relevant metric for forecasting election outcomes. By modeling the percentage of support, we can quantify how various factors—such as pollster quality, sample size, and state-level dynamics—influence the candidates' standings in the polls. This outcome variable also allows us to simulate the Electoral College results by aggregating predicted support across different states, which is crucial for determining the likelihood of either candidate winning the presidency.

@fig-support below shows the distribution of support for both candidates across the polls included in the dataset.

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig.pos: "H"
#| label: fig-support
#| fig-cap: Distribution of Support for Kamala Harris and Donald Trump

ggplot(data, aes(x = pct, fill = candidate_name)) +
  geom_histogram(bins = 30, alpha = 0.7, position = "identity") +
  facet_wrap(~ candidate_name) +
  labs(x = "Percentage of Support",
       y = "Count") +
  scale_fill_discrete(name = "Candidates") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

## Predictor variables

In our analysis, we utilized several key predictor variables to model voter support for Kamala Harris and Donald Trump in the 2024 U.S. Presidential Election. These predictor variables were selected based on their expected influence on polling results and their ability to account for variations in polling accuracy and voter behavior across different states.

One of the key predictors is numeric grade, which represents a composite measure of poll quality. This variable accounts for various aspects of a poll’s reliability, such as the transparency of its methodology and the pollster’s historical accuracy. Pollscore, another important predictor, provides a similar measure of poll reliability but focuses more on the specific performance of the polling organization in recent elections.

Transparency score measures how openly polling organizations disclose their methodology and data, which can significantly impact the trustworthiness of the results. Polls with higher transparency scores are given more weight in the model, as they are generally considered more reliable. The sample size of each poll is also included, as larger sample sizes tend to reduce the margin of error and provide more precise estimates of voter support.

Geographic differences in voter preferences are captured through the state variable, which accounts for regional variations in political culture, demographics, and historical voting patterns. Lastly, methodology refers to the techniques and approaches used by the polling organizations, such as whether the poll was conducted online, by phone, or through other means.

All predictor variables—numeric grade, pollscore, transparency score, sample size, state, and methodology—are presented in @tbl-overview_data.

## Cleaning Process and Analysis

The data cleaning process uses R [@citeR] as well as other packages such as tidyverse [@tidyverse], dplyr [@dplyr], janitor [@janitor] and lubridate [@lubridate]. Begin by standardizing column name to ensure consistency and avoid errors during analysis. The dataset was filtered to focus solely on Kamala Harris and Donald Trump, with polls below a numeric grade of 2.7 excluded to maintain high-quality data. Missing state information was categorized as “National” polls, and the poll end dates were converted to a date format to include only polls conducted after the candidates officially declared their candidacies. This ensures the analysis reflects relevant, up-to-date voter preferences. Additionally, transformations such as calculating the number of supporters from the percentage support and encoding a binary variable for the candidates (Harris = 1, Trump = 0) were performed to enhance usability in the regression models.

Some variables were excluded for simplicity and relevance. For example, **'population_full'** and **'answer'** were dropped as they provided redundant or unnecessary information for this analysis. However, key variables like **'pollster'**, **'pollscore'**, **'numeric grade'**, and **'sample size'** were retained because they provide essential insights into the quality and precision of the polls, directly influencing the reliability of the models. These steps ensured the cleaned dataset was ready for analysis, with a focus on the most important predictors of voter support while minimizing extraneous information.


# Modeling Support for the Candidates {#sec-model}

To analyze factors influencing candidate support, we use a linear regression model with sample size as the primary predictor. This model examines the relationship between sample size and the percentage of support for Kamala Harris and Donald Trump across different polls. By including sample size as a predictor, we can assess whether larger or smaller sample sizes impact reported support levels for each candidate.

```{r}
#| echo: false
#| message: false
#| warning: false
# Load necessary library
library(ggplot2)

# Filter the data for only "Kamala Harris"
harris_data <- subset(data, candidate_name == "Kamala Harris")

# Perform a simple linear regression with pct as the dependent variable and sample_size as the independent variable
model <- lm(pct ~ sample_size, data = harris_data)
```

For Kamala Harris, the linear regression results show that sample size has a statistically insignificant effect on her support percentage. This implies that other factors, such as pollster methodology or regional biases, may play a more substantial role in shaping her reported support.

In contrast, the results for Donald Trump indicate a weak but statistically significant negative effect of sample size on his support percentage. This suggests that, on average, larger sample sizes tend to show slightly lower support for Trump, though the effect size remains small.

Figures @fig-harris-samplesize-supportpct and @fig-trump-samplesize-supportpct illustrate the relationship between sample size and support percentage for Kamala Harris and Donald Trump, respectively. These plots provide a visual representation of the trends observed in the linear regression models for each candidate.


```{r}
#| echo: false
#| message: false
#| warning: false
# Load necessary library
library(ggplot2)

# Filter the data for only "Kamala Harris"
trump_data <- subset(data, candidate_name == "Donald Trump")

# Perform a simple linear regression with pct as the dependent variable and sample_size as the independent variable
model <- lm(pct ~ sample_size, data = trump_data)


```

```{r}
#| echo: false
#| message: false
#| warning: false

mlr_harris_model <- readRDS(here::here(("models/mlr_harris_model.rds")))
mlr_trump_model <- readRDS(here::here(("models/mlr_trump_model.rds")))
```

## Multiple Linear Regression Models

To better capture the complexity of voter support, we constructed multiple linear regression (MLR) models for both Kamala Harris and Donald Trump. These models incorporate key predictors, including pollster rating (represented by pollscore), transparency score, sample size, and state-level data. By including these variables, the MLR models aim to control for multiple factors influencing voter support and to enhance the accuracy of our predictions.

The MLR model for Kamala Harris indicates that factors such as state and pollster rating significantly impact her predicted level of support across polls. The results, shown in @fig-mlr-harris, suggest that Harris's support varies substantially by state and depends on the credibility of the pollster. Diagnostic checks, including residual and QQ plots, confirm that the model reasonably meets linear regression assumptions.

Similarly, the MLR model for Donald Trump highlights that state-level differences and pollster transparency play a significant role in explaining his support. Figure @fig-mlr-trump illustrates these findings, and diagnostic evaluations confirm that the model assumptions (linearity, independence, and homoscedasticity) are sufficiently met.


## Multicollinearity Check Using Variance Inflation Factor (VIF)

To ensure that the predictors used in both models do not exhibit multi-collinearity, we checked the Variance Inflation Factor (VIF) for each predictor. High VIF values indicate multi-collinearity, which can affect the stability and reliability of the model coefficients.

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-harris-vif
#| tbl-cap: Harris MLR model Variance Inflation Factor (VIF) 

# Check VIF for Kamala Harris model
kable(vif(mlr_harris_model), digits=3)

mlr_harris_model_refined <- readRDS(here::here(("models/mlr_harris_model_refined.rds")))
```

Based on the VIF results in @tbl-harris-vif, we refined the model by removing less significant predictors (such as methodology and transparency_score) to reduce multi-collinearity.This improves the model's accuracy and interpretability.


```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-harris-refined-vif
#| tbl-cap: Harris Refined MLR model Variance Inflation Factor (VIF) 

# Refine the model by removing less significant predictors 
# (e.g., methodology and transparency_score)

# Check VIF for the refined model
kable(vif(mlr_harris_model_refined), digits=3)

step_model <- step(mlr_harris_model_refined, direction = "both", trace=0)
```

## Stepwise Model Selection


To refine the multi-linear regression model, I applied a stepwise selection method to optimize the choice of predictor variables. Stepwise selection evaluates the model iteratively, adding or removing variables based on predefined criteria (typically AIC) to find a more parsimonious model. Using both forward and backward selection, stepwise method in the step() function assesses each predictor's contribution and determines if adding or removing it improves model fit. By allowing the function to examine variables in both directions, this process systematically removed non-significant variables that did not contribute meaningfully to the model's explanatory power, leaving only the most impactful predictors in the final refined model. The resulting plots, showing the "Residuals vs Fitted" and "Normal Q-Q" diagnostic views, allow for visual inspection of model assumptions and residual patterns, supporting the quality of the refined model.

## National-Level Model Evaluation and Predictive Accuracy

After finalizing the model selection process, we evaluated the predictive performance of our models for Kamala Harris and Donald Trump using national-level polling data. Focusing on national polls, we split the dataset into training and test sets, maintaining consistency with a fixed random seed to ensure reproducibility. For each candidate, we developed a multiple linear regression model using pollscore and a log-transformed sample_size as predictors, capturing factors pertinent to national-level polling dynamics.

We then trained the models on the training subset and generated predictions for the test subset, evaluating model accuracy using the Root Mean Squared Error (RMSE). The RMSE metric quantifies the average prediction error in the test set, offering an indication of each model’s reliability in predicting future national poll outcomes. The Harris model yielded an RMSE of 3.12, while the Trump model’s RMSE was 2.40, indicating that both models provide reasonably accurate predictions, with the Trump model demonstrating slightly lower average error in predicting national polling support. These results reflect the models’ robustness and highlight their utility for assessing national-level candidate support.

# Electoral College Prediction {#sec-predict}

To forecast the winner of the 2024 U.S. Presidential election between Kamala Harris and Donald Trump, we performed the following series of steps, focusing on the distribution of electoral votes across states based on predicted polling percentages. This approach allows for an estimation of each candidate's electoral college support under the U.S. voting system.

1. Predicting State-Level Polling Percentages: We used final multiple linear regression models for both candidates, Harris and Trump. These models generated predicted polling percentages for each candidate across different states, capturing their expected levels of support based on the poll data used.

2. Averaging Predicted Support by State: For both Harris and Trump, we calculated the average predicted polling percentage within each state. This step provides a state-level summary of each candidate's support based on our predictions, simplifying comparisons between them in each state.

3. Assigning Electoral Votes: We then merged our state-level predictions with the distribution of electoral votes, as assigned by state in the Electoral College. This dataset provided the electoral vote count for each state, including special allocations for districts in Maine and Nebraska, which can split their electoral votes by congressional district.

4. Determining State Winners: Using the averaged predictions, we identified the winner in each state by comparing the predicted support percentages. Harris or Trump was deemed the winner in a state if their predicted polling percentage exceeded that of their opponent.

5. Aggregating Electoral Votes: Finally, we summed the electoral votes for each candidate across all states where they were predicted to win. This yielded total electoral vote counts for both Harris and Trump, which are essential for determining the predicted winner under the U.S. system, where 270 electoral votes are required to secure the presidency.

6. Interpreting the Results: With Harris predicted to receive 216 electoral votes compared to Trump’s 147, Harris demonstrates a stronger position in the Electoral College, though neither candidate reaches the 270-vote threshold required for a decisive victory. This outcome suggests that, while a clear electoral win is not forecasted, Harris holds a better chance of winning the election based on her lead in projected electoral votes. This lead places her closer to the threshold and may indicate a competitive advantage should undecided states or close races lean in her favor.


This electoral vote aggregation based on state-level predictions provides an interpretation of how polling data (@fig-predicted-vote-pct), analyzed through multiple linear regression models, translates into likely electoral support for each candidate. It effectively models potential election outcomes while respecting the structure of the Electoral College​​.




# Discussion {#sec-discuss}

## Key Findings

This study set out to forecast the outcome of the 2024 U.S. Presidential Election between Kamala Harris and Donald Trump by developing a multiple linear regression (MLR) model based on comprehensive polling data. Importantly, the same MLR model was applied to both candidates, ensuring consistency in how predictors influenced the predicted support percentages for each.

The MLR model incorporated several significant predictors of voter support, including state-level factors, pollster ratings (pollscore), transparency scores, and sample size. By using the same model for both Harris and Trump, we were able to directly compare how these variables impacted each candidate's predicted support across different states.

For both Kamala Harris and Donald Trump, the model highlighted the substantial impact of state-level variations on their predicted support. Certain states showed higher predicted support for Harris, such as California and Maryland, which historically lean Democratic. Conversely, states like Indiana and Missouri exhibited higher predicted support for Trump, aligning with their Republican-leaning tendencies. The consistency of the model across both candidates allowed for a clear comparison of how state demographics and historical voting patterns influenced voter preferences.

Pollster reliability indicators, such as numeric grades and transparency scores, were significant predictors for both candidates. This suggests that polls conducted by more credible organizations tended to report more accurate and potentially higher support levels for each candidate. The sample size also played a role, although its impact varied slightly between the two candidates. By using the same model, we ensured that these predictors were weighted equally in the analysis of both Harris's and Trump's support levels.

When aggregating the state-level predictions to simulate the Electoral College outcomes, the findings suggest a competitive race. Harris is projected to receive 216 electoral votes, while Trump is predicted to secure 147 electoral votes. Neither candidate reaches the 270-vote threshold required to win the presidency, emphasizing the potential for a closely contested election. The remaining electoral votes are likely concentrated in battleground states, where voter preferences are more volatile and could ultimately determine the election outcome.

## Model Strengths

A primary strength of this analysis lies in the consistent application of the same MLR model to both candidates. This approach ensures that the comparison between Harris and Trump is based on the same criteria and that any differences in predicted support are attributable to variations in the data rather than differences in the modeling approach.

By incorporating multiple predictors—including state-level data, pollster ratings, transparency scores, and sample size—the model provides a nuanced understanding of the factors influencing voter preferences. This multifaceted approach allows for more accurate predictions compared to models relying solely on national-level polling data or a single set of predictors.

The use of stepwise model selection and checks for multicollinearity enhanced the robustness of the MLR model. Stepwise selection optimized the predictor variables, ensuring that only those contributing significantly to the model were included. Checking for multicollinearity through the Variance Inflation Factor (VIF) helped prevent unreliable estimates due to correlated predictors, thereby improving the model's validity for both candidates.

Moreover, translating the predicted support percentages into Electoral College projections adds practical value to the analysis. Since the U.S. Presidential Election is determined by electoral votes rather than the popular vote, this approach offers a more realistic forecast of the election outcome. Using the same model for both candidates ensures that the Electoral College projections are directly comparable.

## Limitations

Despite the strengths, several limitations need to be acknowledged:

- Reliance on Polling Data Quality: The accuracy of the model is inherently dependent on the quality of the polling data used. While the analysis accounted for pollster ratings and transparency scores, inherent biases and methodological differences between polls could still affect the results. Sampling errors, non-response biases, and underrepresentation of certain demographic groups are persistent issues in polling data that can skew predictions for both candidates.

- Static Snapshot of Voter Preferences: The model provides a static view based on the most recent polling data available. It does not account for the dynamic nature of election campaigns, where voter preferences can shift rapidly due to various factors such as political events, debates, or emerging issues. This limitation means the model may not accurately predict future changes in voter sentiment leading up to the election for either candidate.

- Exclusion of Other Influential Factors: The analysis did not incorporate other variables that can significantly impact election outcomes, such as economic indicators (e.g., unemployment rates, GDP growth), social movements, campaign strategies, or voter turnout efforts. The absence of these factors may limit the model's ability to fully capture the complexities of voter behavior for both Harris and Trump.

- Electoral College Simplifications: The Electoral College simulation assumes that the candidate with the higher predicted support in a state wins all its electoral votes (except for Maine and Nebraska). This winner-takes-all approach does not account for the proportional allocation of electoral votes in those two states or potential variations in voter turnout that could affect the actual results.

## Future Research 
To enhance the predictive power and accuracy of election forecasting models, future research could consider the following approaches:

- Incorporate Time-Series Analysis: Introducing a time-series component would allow the model to account for trends and shifts in voter preferences over time. This dynamic approach could capture the impact of events such as debates, policy announcements, or external factors on voter sentiment for both candidates.

- Expand Predictive Variables: Including additional variables such as economic indicators, demographic data, and social media sentiment analysis could provide a more comprehensive view of the factors influencing voter behavior. Integrating data on unemployment rates or consumer confidence might reveal economic influences on candidate support.

- Voter Turnout Models: Developing models to predict voter turnout could significantly improve election forecasts. Turnout can vary widely between elections and is often influenced by voter enthusiasm, mobilization efforts, and barriers to voting. Incorporating turnout probabilities could adjust the predicted support percentages to reflect more realistic electoral scenarios.

- Advanced Modeling Techniques: Exploring advanced statistical methods or machine learning algorithms might capture complex nonlinear relationships between predictors and voter support. Techniques such as random forests, gradient boosting, or neural networks could uncover patterns not detectable through linear regression.

- Account for Electoral Nuances: With variations in how electoral votes are allocated and the potential impact of third-party candidates or ranked-choice voting in some states, future models should consider these electoral nuances. Simulating different voting systems could provide insights into how alternative methods might affect election outcomes.

- Cross-Validation with Alternative Data Sources: Validating the model against alternative data sources, such as exit polls or historical voting patterns, could test its robustness. Cross-validation helps ensure that the model is not overfitted to the polling data used and can generalize to different datasets.

\newpage

\appendix

# Appendix

## YouGov Pollster Methodology Overview and Evaluation
YouGov conducts online surveys through their proprietary panel of U.S. adults, using nonprobability sampling methods combined with sophisticated weighting procedures to achieve representative results. Their approach balances speed and cost-effectiveness with statistical rigor through careful sample selection and data quality controls.

### Survey Population and Sampling
YouGov's target population typically comprises all U.S. adults or adult citizens, with their sampling frame consisting of their opt-in online panel covering approximately 95% of Americans. For general population surveys, they aim for 1,000-2,000 respondents, selected based on demographic and political characteristics to match the target population.

### Panel Recruitment and Participation
Panel members are recruited through advertising and website partnerships, with surveys offered in multiple languages including Spanish to ensure broad representation. Participants receive points exchangeable for small monetary rewards, though many report being motivated by the desire to contribute to research.

### Quality Control
YouGov employs several measures to maintain data quality:

- Verification of panelist identity through email and IP checks
- Response quality surveys to gauge reliability
- Monitoring of response times and patterns
- Removal of respondents who fail quality checks
- Question randomization to reduce bias

### Non-response and Weighting
To address potential biases, YouGov applies statistical weighting based on demographics (age, gender, race, education) and political factors (voting behavior, party identification). Their weighting process considers multiple characteristics simultaneously to better reflect real-world demographic intersections.

### Strengths and Limitations
The methodology's primary strengths include rapid data collection, cost-effectiveness, and the ability to track opinions over time. However, the nonprobability sampling approach may introduce biases, and the online-only format could underrepresent certain populations. While weighting helps address these limitations, it cannot fully account for all potential sources of bias.


## Idealized Survey Methodology
This idealized survey methodology outlines a comprehensive plan for forecasting the US presidential election within a budget of $100,000. The approach is designed to be statistically sound, practical, and capable of accurately predicting election outcomes by considering both the popular vote and electoral college implications.

### Sampling Strategy
The target population for this survey is eligible voters across the United States who are likely to participate in the upcoming presidential election. To achieve a representative sample:

- **Sampling Frame:** Utilize a combination of registered voter lists and demographic data from reputable sources such as the US Census Bureau.
- **Sampling Method:** Implement stratified random sampling to ensure representation across key demographics, including age, gender, race, education level, and geographic location.
- **Sample Size Calculation:** Aim for a sample size of approximately 10,000 respondents to achieve a margin of error of ±1% at a 95% confidence level.
- **Geographical Distribution:** Allocate samples proportionally across all 50 states and the District of Columbia, with oversampling in swing states to better predict electoral college outcomes.
- **Addressing Sampling Biases:** Apply weighting adjustments to account for underrepresented groups and ensure that the sample mirrors the overall voter population.

### Recruitment Plan
To recruit respondents effectively, we will leverage online panels, social media advertising, and partnerships with community organizations to reach a diverse audience. Offering modest incentives, such as $5 digital gift cards, encourages participation while managing costs. Quota sampling within strata maintains demographic balance, and follow-up reminders along with mobile-friendly survey formats help reduce non-response bias. The data collection will occur over a two-week period to capture timely opinions without introducing temporal biases.

### Survey Design Elements
The survey is crafted to elicit accurate and meaningful responses:

- **Question Types and Formats:** Use a mix of closed-ended questions and multiple-choice options for clarity and ease of analysis.
- **Response Options:** Include balanced and neutral response choices, with options for "Undecided" or "Prefer not to say."
- **Question Order and Flow:** Begin with general questions to build rapport, followed by more specific vote intention queries, and conclude with demographic questions.
- **Demographic Information:** Collect data on age, gender, race, education, income, and geographic location.
- **Political Affiliation and History:** Ask about party affiliation, past voting behavior, and political engagement.
- **Likely Voter Screens:** Include questions to gauge voting likelihood, such as past voting frequency and intention to vote in the upcoming election.
- **Vote Intention Questions:** Directly ask which candidate the respondent intends to vote for, ensuring confidentiality and anonymity.

### Quality Control
To maintain data integrity, we implement several quality control measures. Real-time validation checks within the survey prevent inconsistent or illogical responses. Attention-check questions identify disengaged respondents. We use unique survey links and track IP addresses to prevent duplicate submissions, while CAPTCHA verification deters automated responses. Incomplete or suspicious responses are excluded during data cleaning to ensure the final dataset is robust and reliable.

### Data Processing
These data processing steps will be taken to ensure accurate analysis:

- **Weighting Methodology:** Adjust survey results using weighting factors based on demographic proportions in the voting population.
- **Handling Missing Data:** Employ imputation techniques or exclude cases with significant missing information.
- **Outlier Detection:** Identify and review outliers that may skew results, determining whether to retain or discard them.
- **Response Validation:** Cross-check responses for consistency and plausibility.
- **Poll Aggregation Approach:** Combine survey data with other reputable polls using meta-analytic techniques to enhance prediction accuracy.

### Budget Allocation
A budget allocation of $100,000 ensures all aspects are adequately funded:

- **Recruitment Costs:** $40,000 for advertising and partnerships to reach potential respondents.
- **Incentive Payments:** \$50,000 allocated for participant incentives ($5 x 10,000 respondents).
- **Survey Platform Fees:** $2,000 for premium features on a survey platform like Google Forms or an equivalent.
- **Data Analysis Tools:** $3,000 for statistical software licenses and data processing tools.
- **Quality Control Measures:** $3,000 for implementing validation systems and CAPTCHA services.
- **Administrative Costs:** $2,000 for project management and miscellaneous expenses.

### Conclusion
This methodology presents a feasible and thorough plan to forecast the US presidential election within the specified budget. By adhering to best practices in survey design and execution, and by carefully considering both the popular vote and electoral college implications, the survey aims to provide accurate and reliable insights into voter intentions.


\newpage

# Appendix 

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: tbl-overview_data

data_overview <- data %>%
  select(poll_id, pollster, pollscore, sample_size, pct, state, candidate_name, end_date)

# Transpose the first 5 rows to display them vertically
data_overview_transposed <- data_overview %>%
  head(5) %>%
  t()

# Display the transposed table with a caption
data_overview_transposed %>%
  kable(caption = "Sample Overview of Selected Variables in the Polling Dataset")

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-harris-samplesize-supportpct
#| fig-cap: Linear Regression of Percentage vs Sample Size for Kamala Harris

# Plot the relationship for Kamala Harris
ggplot(harris_data, aes(x = sample_size, y = pct)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  labs(x = "Sample Size",
       y = "Percentage")
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-trump-samplesize-supportpct
#| fig-cap: Linear Regression of Percentage vs Sample Size for Donald Trump

# Plot the relationship for Trump
ggplot(trump_data, aes(x = sample_size, y = pct)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  labs(x = "Sample Size",
       y = "Percentage")
```
```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-mlr-harris
#| fig-cap: Multi-Linear Regression model for Kamala Harris
#| fig.width: 10
#| fig.height: 4

mlr_harris_model <- readRDS(here::here(("models/mlr_harris_model.rds")))

# For Harris model
par(mfrow = c(1, 2))  # Set layout for 1 row and 2 columns
plot(mlr_harris_model, which = c(1, 2))  # 1: Residuals vs Fitted, 2: Normal Q-Q
par(mfrow = c(1, 1))  # Reset plot layout

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-mlr-trump
#| fig-cap: Multi-Linear Regression model for Donald Trump
#| fig.width: 10
#| fig.height: 4

# Load the saved MLR model for Donald Trump
mlr_trump_model <- readRDS(here::here(("models/mlr_trump_model.rds")))

# For Trump model
par(mfrow = c(1, 2))  # Set layout for 1 row and 2 columns
plot(mlr_trump_model, which = c(1, 2))  # 1: Residuals vs Fitted, 2: Normal Q-Q
par(mfrow = c(1, 1))  # Reset plot layout

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-harris-vif
#| fig-cap: Harris Refined Multi-Linear Regression Model
#| fig.width: 10
#| fig.height: 4

# Refine the model by removing less significant predictors 
# (e.g., methodology and transparency_score)
mlr_harris_model_refined <- readRDS(here::here(("models/mlr_harris_model_refined.rds")))

# For Harris refined model
par(mfrow = c(1, 2))  # Set layout for 1 row and 2 columns
plot(mlr_harris_model_refined, which = c(1, 2))  # 1: Residuals vs Fitted, 2: Normal Q-Q
par(mfrow = c(1, 1))  # Reset plot layout

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| label: fig-harris-step
#| fig-cap: Harris Final Multi-Linear Regression Model
#| fig.width: 10
#| fig.height: 4

# Perform stepwise selection to optimize the Harris model
step_model <- step(mlr_harris_model_refined, direction = "both", trace=0)

# For Harris stepwise model
par(mfrow = c(1, 2))  # Set layout for 1 row and 2 columns
plot(step_model, which = c(1, 2))  # 1: Residuals vs Fitted, 2: Normal Q-Q
par(mfrow = c(1, 1))  # Reset plot layout

```

```{r, out.width="90%", out.height="70%", fig.align="center"}
#| echo: false
#| message: false
#| warning: false
#| label: fig-predicted-vote-pct
#| fig-cap: Predicted Vote Percentages by State
knitr::include_graphics(here::here(("improved_vote_percentages_by_state.png")))

```

\newpage

# References
